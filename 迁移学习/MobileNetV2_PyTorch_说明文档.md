# MobileNetV2迁移学习 - PyTorch实现

## 项目概述

本项目使用PyTorch框架实现基于MobileNetV2的迁移学习，在MNIST手写数字数据集上进行分类任务。该项目展示了如何使用预训练模型进行迁移学习，包括特征提取和模型微调两个阶段。

## 技术栈

- **深度学习框架**: PyTorch 2.7.1+
- **计算机视觉**: torchvision
- **数据处理**: NumPy
- **可视化**: Matplotlib, Seaborn
- **评估指标**: Scikit-learn

## 项目结构

```
迁移学习/
├── MobileNetV2.ipynb                    # 主要代码文件
├── MobileNetV2_PyTorch_说明文档.md      # 本说明文档
└── data/                                # 数据目录（自动创建）
    └── MNIST/                           # MNIST数据集
```

## 代码结构详解

### 1. 数据准备 (Cell 2)

```python
# 核心功能
- 自动下载MNIST数据集
- 数据预处理：单通道→三通道转换
- 图像尺寸调整：28x28 → 32x32
- 数据归一化和标准化
- 创建PyTorch数据加载器
```

**关键特性**：
- 使用`transforms.Grayscale(num_output_channels=3)`将灰度图转换为RGB格式
- 通过`transforms.Resize((32, 32))`调整图像尺寸以适应MobileNetV2输入要求
- 批处理大小设置为32，平衡内存使用和训练效率

### 2. 模型构建 (Cell 4)

```python
class MobileNetV2Classifier(nn.Module):
    def __init__(self, num_classes=10, pretrained=True):
        # 加载预训练MobileNetV2模型
        # 冻结所有预训练层
        # 替换分类器层
```

**设计亮点**：
- 继承`nn.Module`实现自定义分类器
- 加载ImageNet预训练权重
- 初始阶段冻结所有预训练参数
- 自定义分类器：Dropout(0.2) + Linear层

### 3. 初始训练 (Cell 6)

**训练策略**：
- 仅训练新添加的分类器层
- 使用Adam优化器，学习率0.001
- 交叉熵损失函数
- 10个epoch的初始训练

**监控指标**：
- 实时损失值
- 批次和epoch级别的准确率
- 训练进度可视化

### 4. 模型微调 (Cell 8)

**微调策略**：
- 解冻MobileNetV2的后4层
- 差异化学习率设置：
  - 分类器层：0.001
  - 解冻的特征层：0.0001（较小学习率保护预训练特征）
- 5个epoch的微调训练

### 5. 模型评估 (Cell 10)

**评估指标**：
- 测试损失
- 测试准确率
- 预测结果存储（用于后续分析）

### 6. 性能可视化 (Cell 12)

**可视化内容**：
- 混淆矩阵热图
- 详细分类报告
- 各类别精确率、召回率、F1分数

### 7. 结果展示 (Cell 14)

**可视化功能**：
- 随机样本预测结果展示
- 正确/错误预测的颜色区分
- 训练过程曲线：
  - 损失曲线（初始训练+微调）
  - 准确率曲线（初始训练+微调）

## 技术特点

### 迁移学习优势
1. **快速收敛**: 利用预训练权重加速训练
2. **小数据集友好**: 在有限数据上获得良好性能
3. **计算效率**: 减少训练时间和计算资源需求

### MobileNetV2优势
1. **轻量级架构**: 参数量小，适合移动端部署
2. **高效推理**: 优化的卷积结构提高推理速度
3. **良好的特征提取能力**: 在多种视觉任务上表现优异

### 代码特色
1. **模块化设计**: 清晰的函数分离和类封装
2. **设备自适应**: 自动检测并使用GPU/CPU
3. **中文友好**: 支持中文可视化显示
4. **完整监控**: 详细的训练过程监控和可视化

## 使用说明

### 环境要求
```bash
# 核心依赖
torch>=2.0.0
torchvision>=0.15.0
numpy
matplotlib
seaborn
scikit-learn
```

### 运行步骤
1. 确保安装所需依赖包
2. 按顺序执行notebook中的所有cell
3. 首次运行会自动下载MNIST数据集
4. 根据硬件配置调整batch_size和epoch数量

### 参数调优建议
- **学习率**: 根据收敛情况调整初始学习率
- **微调层数**: 可以尝试解冻更多或更少的层
- **训练epoch**: 根据验证集性能决定训练轮数
- **数据增强**: 可添加随机旋转、缩放等增强技术

## 性能预期

**典型结果**：
- 初始训练后准确率: ~85-90%
- 微调后准确率: ~90-95%
- 训练时间: 约10-20分钟（取决于硬件）

## 扩展方向

1. **数据集扩展**: 适配CIFAR-10、Fashion-MNIST等数据集
2. **模型对比**: 与ResNet、EfficientNet等模型对比
3. **部署优化**: 模型量化、剪枝等优化技术
4. **实际应用**: 集成到移动应用或Web服务

## 常见问题

**Q: 为什么要将MNIST转换为3通道？**
A: MobileNetV2预训练模型期望RGB输入，转换后可以利用预训练权重。

**Q: 如何选择微调的层数？**
A: 通常从网络后部开始，根据任务相似性和数据量决定解冻层数。

**Q: 训练过程中出现过拟合怎么办？**
A: 可以增加Dropout、减少学习率、使用数据增强或早停策略。

## 参考资料

- [MobileNetV2论文](https://arxiv.org/abs/1801.04381)
- [PyTorch迁移学习教程](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [torchvision模型文档](https://pytorch.org/vision/stable/models.html)

---

**作者**: [您的姓名]  
**更新时间**: 2025年7月13日  
**版本**: 1.0
